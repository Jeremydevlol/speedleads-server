// services/visionService.js - Ahora usando OpenAI GPT-5.2 para visi√≥n y OCR
import OpenAI from 'openai';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY,
  timeout: 60000,
  maxRetries: 2,
});

const VISION_MODEL = 'gpt-4o';

/**
 * Analiza un buffer de imagen usando OpenAI GPT-5.2 Vision (reemplaza Google Vision)
 * @param imageBuffer - Buffer de la imagen a analizar
 * @returns Texto detectado en la imagen (cadena vac√≠a si no se encuentra texto)
 */
export async function analyzeImageBufferWithVision(imageBuffer) {
    try {
        console.log('üñºÔ∏è Iniciando an√°lisis de imagen con OpenAI GPT-5.2 Vision...');
        console.log(`üìä Tama√±o de imagen: ${(imageBuffer.length / 1024).toFixed(2)}KB`);
        
        // Convertir buffer a base64
        const base64Image = imageBuffer.toString('base64');
        const mimeType = detectImageMimeType(imageBuffer);
        
        const response = await openai.chat.completions.create({
            model: VISION_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Eres un experto en OCR (Reconocimiento √ìptico de Caracteres). Tu tarea es extraer TODO el texto visible en la imagen de forma precisa y completa. 
                    
INSTRUCCIONES:
- Extrae todo el texto visible, manteniendo el formato original lo mejor posible
- Incluye n√∫meros, fechas, direcciones, nombres, todo texto legible
- Si hay texto en diferentes secciones, sep√°ralos con saltos de l√≠nea
- Si la imagen no contiene texto legible, responde exactamente: "NO_TEXT_FOUND"
- NO a√±adas explicaciones ni comentarios, solo el texto extra√≠do
- Mant√©n el idioma original del texto`
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:${mimeType};base64,${base64Image}`,
                                detail: 'high' // Alta resoluci√≥n para mejor OCR
                            }
                        },
                        {
                            type: 'text',
                            text: 'Extrae todo el texto visible en esta imagen.'
                        }
                    ]
                }
            ],
            max_tokens: 4000,
            temperature: 0.1 // Baja temperatura para mayor precisi√≥n en OCR
        });

        const extractedText = response.choices[0]?.message?.content?.trim() || '';
        
        // Si no se encontr√≥ texto
        if (extractedText === 'NO_TEXT_FOUND' || extractedText.toLowerCase().includes('no hay texto') || extractedText.toLowerCase().includes('no contiene texto')) {
            console.log('üìù No se encontr√≥ texto en la imagen');
            return '';
        }
        
        console.log(`‚úÖ An√°lisis de imagen completado. Texto extra√≠do: ${extractedText.length} caracteres`);
        return extractedText;
        
    } catch (error) {
        console.error('‚ùå Error al analizar la imagen con OpenAI:', error);
        
        if (error.code === 'invalid_api_key') {
            throw new Error('API Key de OpenAI no v√°lida');
        }
        if (error.code === 'rate_limit_exceeded') {
            throw new Error('L√≠mite de API de OpenAI excedido');
        }
        if (error.message?.includes('Could not process image')) {
            throw new Error('Formato de imagen no v√°lido o corrupto');
        }
        
        console.error('Detalles del error:', {
            code: error.code,
            message: error.message,
            status: error.status
        });
        
        throw new Error('Error al procesar la imagen con OpenAI Vision');
    }
}

/**
 * Versi√≥n alternativa para analizar im√°genes desde URL
 * @param imageUrl - URL p√∫blica de la imagen
 * @returns Texto detectado en la imagen
 */
export async function analyzeImageUrlWithVision(imageUrl) {
    try {
        console.log('üñºÔ∏è Analizando imagen desde URL con OpenAI GPT-5.2...');
        
        const response = await openai.chat.completions.create({
            model: VISION_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Eres un experto en OCR. Extrae TODO el texto visible en la imagen de forma precisa. Si no hay texto, responde "NO_TEXT_FOUND".`
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: imageUrl,
                                detail: 'high'
                            }
                        },
                        {
                            type: 'text',
                            text: 'Extrae todo el texto visible en esta imagen.'
                        }
                    ]
                }
            ],
            max_tokens: 4000,
            temperature: 0.1
        });

        const extractedText = response.choices[0]?.message?.content?.trim() || '';
        
        if (extractedText === 'NO_TEXT_FOUND') {
            return '';
        }
        
        return extractedText;
        
    } catch (error) {
        console.error('Error al analizar la imagen (URL):', error);
        throw new Error('Error al procesar la imagen desde URL');
    }
}

/**
 * Detecta si una imagen contiene contenido expl√≠cito usando OpenAI
 * @param imageBuffer - Buffer de la imagen
 * @returns True si la imagen es segura
 */
export async function isImageSafe(imageBuffer) {
    try {
        console.log('üõ°Ô∏è Verificando seguridad de imagen con OpenAI...');
        
        const base64Image = imageBuffer.toString('base64');
        const mimeType = detectImageMimeType(imageBuffer);
        
        const response = await openai.chat.completions.create({
            model: VISION_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Eres un moderador de contenido. Analiza la imagen y determina si es segura.
                    
Responde SOLO con un JSON en este formato exacto:
{"safe": true/false, "reason": "breve explicaci√≥n"}

Una imagen NO es segura si contiene:
- Contenido sexual expl√≠cito o sugestivo
- Violencia gr√°fica
- Gore o contenido perturbador
- Desnudez inapropiada

Si la imagen es normal/segura, responde {"safe": true, "reason": "contenido apropiado"}`
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:${mimeType};base64,${base64Image}`,
                                detail: 'low' // Baja resoluci√≥n es suficiente para moderaci√≥n
                            }
                        },
                        {
                            type: 'text',
                            text: '¬øEsta imagen es segura?'
                        }
                    ]
                }
            ],
            max_tokens: 200,
            temperature: 0
        });

        const result = response.choices[0]?.message?.content?.trim() || '{"safe": true}';
        
        try {
            const parsed = JSON.parse(result);
            console.log(`üõ°Ô∏è Resultado de seguridad: ${parsed.safe ? 'SEGURA' : 'NO SEGURA'} - ${parsed.reason || ''}`);
            return parsed.safe === true;
        } catch {
            // Si no puede parsear, asumir seguro
            console.log('‚ö†Ô∏è No se pudo parsear respuesta de seguridad, asumiendo seguro');
            return true;
        }
        
    } catch (error) {
        console.error('Error en detecci√≥n de contenido seguro:', error);
        return true; // En caso de error, asumir seguro para no bloquear
    }
}

/**
 * Analiza un PDF usando OpenAI GPT-5.2 Vision
 * @param buffer - Buffer del PDF
 * @returns Texto extra√≠do del PDF
 */
export async function analyzePdfBufferWithVision(buffer) {
    try {
        console.log('üìÑ Iniciando an√°lisis de PDF con OpenAI GPT-5.2...');
        console.log(`üìÑ Tama√±o del PDF: ${(buffer.length / 1024 / 1024).toFixed(2)}MB`);
        
        // Convertir PDF a base64
        const base64Pdf = buffer.toString('base64');
        
        const response = await openai.chat.completions.create({
            model: VISION_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Eres un experto en extracci√≥n de texto de documentos PDF. Tu tarea es extraer TODO el contenido textual del PDF de forma precisa y estructurada.

INSTRUCCIONES:
- Extrae todo el texto visible en todas las p√°ginas
- Mant√©n la estructura del documento (t√≠tulos, p√°rrafos, listas)
- Incluye tablas formateadas de manera legible
- Incluye n√∫meros, fechas, direcciones, todo texto legible
- Si hay m√∫ltiples p√°ginas, sep√°ralas con "--- P√°gina X ---"
- Si el PDF es una imagen escaneada, usa OCR
- NO a√±adas explicaciones, solo el contenido del documento
- Mant√©n el idioma original`
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:application/pdf;base64,${base64Pdf}`,
                                detail: 'high'
                            }
                        },
                        {
                            type: 'text',
                            text: 'Extrae todo el contenido textual de este documento PDF.'
                        }
                    ]
                }
            ],
            max_tokens: 8000, // M√°s tokens para documentos largos
            temperature: 0.1
        });

        const extractedText = response.choices[0]?.message?.content?.trim() || '';
        
        if (!extractedText || extractedText.length === 0) {
            console.log('‚ö†Ô∏è No se encontr√≥ texto en el PDF');
            return 'PDF procesado pero no se encontr√≥ texto legible. Puede ser un PDF de solo im√°genes o con texto no reconocible.';
        }
        
        console.log(`‚úÖ An√°lisis de PDF completado exitosamente. Texto extra√≠do: ${extractedText.length} caracteres`);
        console.log(`üìÑ Muestra del texto: ${extractedText.substring(0, 200)}...`);
        
        return extractedText;
        
    } catch (error) {
        console.error('‚ùå Error al analizar el PDF:', error);
        
        if (error.message?.includes('Could not process')) {
            console.error('‚ùå Error de formato: PDF no v√°lido o corrupto');
            return 'PDF procesado pero el formato no es v√°lido o est√° corrupto';
        }
        if (error.code === 'rate_limit_exceeded') {
            console.error('‚ùå Error de l√≠mite: L√≠mite de API excedido');
            return 'PDF procesado pero se excedi√≥ el l√≠mite de procesamiento';
        }
        
        console.error('Detalles del error de PDF:', {
            code: error.code,
            message: error.message,
            status: error.status
        });
        
        return `PDF procesado pero no se pudo extraer texto: ${error.message}`;
    }
}

/**
 * An√°lisis visual completo de una imagen usando OpenAI GPT-5.2
 * Incluye: objetos, marcas, caras, colores, etiquetas, texto, etc.
 * @param imageBuffer - Buffer de la imagen a analizar
 * @returns Objeto con an√°lisis completo de la imagen
 */
export async function analyzeImageComplete(imageBuffer) {
    try {
        console.log('üîç Iniciando an√°lisis visual completo con OpenAI GPT-5.2...');
        console.log(`üìä Tama√±o de imagen: ${(imageBuffer.length / 1024).toFixed(2)}KB`);
        
        const base64Image = imageBuffer.toString('base64');
        const mimeType = detectImageMimeType(imageBuffer);
        
        const response = await openai.chat.completions.create({
            model: VISION_MODEL,
            messages: [
                {
                    role: 'system',
                    content: `Eres un experto analizador de im√°genes GENERAL. Tu an√°lisis debe ser PRECISO, ESPEC√çFICO y aplicable a CUALQUIER tipo de imagen.

INSTRUCCIONES IMPORTANTES:
1. Analiza TODO lo que veas: personas, objetos, animales, paisajes, documentos, productos, veh√≠culos, etc.
2. Identifica marcas, logos, texto visible con precisi√≥n
3. Si hay personas, describe expresiones, vestimenta, actividades
4. Si hay productos, identifica marca, tipo, caracter√≠sticas
5. Si es un documento, extrae el texto visible
6. Si es un paisaje o lugar, describe la ubicaci√≥n y caracter√≠sticas
7. NO uses frases vagas como "lo que parece ser" - s√© directo y seguro

Responde SOLO con un JSON v√°lido en este formato exacto:
{
    "text": "todo el texto visible en la imagen (vac√≠o si no hay)",
    "objects": ["lista de objetos con nombres espec√≠ficos, no gen√©ricos"],
    "labels": ["categor√≠as precisas que describen la imagen"],
    "logos": ["marcas o logos detectados con nombre exacto"],
    "faces": {
        "count": n√∫mero de caras detectadas (0 si no hay personas),
        "emotions": ["emociones si hay personas"],
        "descriptions": ["descripci√≥n de cada persona si aplica"]
    },
    "colors": ["colores dominantes"],
    "landmarks": ["lugares reconocibles"],
    "safety": {
        "isSafe": true/false,
        "concerns": []
    },
    "contentType": {
        "category": "persona/producto/documento/paisaje/arte/animal/veh√≠culo/comida/otro",
        "subcategory": "subcategor√≠a espec√≠fica",
        "details": {}
    },
    "summary": "Descripci√≥n PRECISA y DIRECTA de 1-2 oraciones describiendo lo que se ve en la imagen",
    "confidence": n√∫mero del 0 al 100,
    "actionableInfo": "Informaci√≥n √∫til extra√≠da que podr√≠a ser usada como instrucci√≥n"
}

S√© PRECISO, ESPEC√çFICO y DIRECTO. Adapta tu an√°lisis al tipo de contenido de la imagen.`
                },
                {
                    role: 'user',
                    content: [
                        {
                            type: 'image_url',
                            image_url: {
                                url: `data:${mimeType};base64,${base64Image}`,
                                detail: 'high'
                            }
                        },
                        {
                            type: 'text',
                            text: 'Analiza esta imagen con precisi√≥n. Identifica todo lo relevante: personas, objetos, texto, marcas, lugares, etc.'
                        }
                    ]
                }
            ],
            max_tokens: 4000,
            temperature: 0.2
        });

        const resultText = response.choices[0]?.message?.content?.trim() || '{}';
        
        try {
            // Intentar parsear el JSON
            let analysis = JSON.parse(resultText);
            
            // Normalizar la estructura para compatibilidad
            const normalizedAnalysis = {
                timestamp: new Date().toISOString(),
                imageSize: imageBuffer.length,
                text: analysis.text || '',
                objects: (analysis.objects || []).map(obj => ({
                    name: typeof obj === 'string' ? obj : obj.name,
                    confidence: typeof obj === 'string' ? 85 : (obj.confidence || 85)
                })),
                labels: (analysis.labels || []).map(label => ({
                    description: typeof label === 'string' ? label : label.description,
                    confidence: typeof label === 'string' ? 80 : (label.confidence || 80)
                })),
                logos: (analysis.logos || []).map(logo => ({
                    description: typeof logo === 'string' ? logo : logo.description,
                    confidence: 90
                })),
                faces: Array.isArray(analysis.faces) ? analysis.faces : [{
                    count: analysis.faces?.count || 0,
                    emotions: analysis.faces?.emotions || []
                }],
                colors: (analysis.colors || []).map(color => ({
                    hex: typeof color === 'string' ? color : color.hex,
                    percentage: 20
                })),
                safety: {
                    isSafe: analysis.safety?.isSafe !== false,
                    concerns: analysis.safety?.concerns || []
                },
                landmarks: (analysis.landmarks || []).map(landmark => ({
                    description: typeof landmark === 'string' ? landmark : landmark.description,
                    confidence: 80
                })),
                summary: analysis.summary || 'Imagen analizada',
                confidence: analysis.confidence || 85
            };
            
            console.log(`‚úÖ An√°lisis visual completo terminado`);
            console.log(`üìä Confianza general: ${normalizedAnalysis.confidence}%`);
            console.log(`üìù Resumen: ${normalizedAnalysis.summary}`);
            
            return normalizedAnalysis;
            
        } catch (parseError) {
            console.error('‚ö†Ô∏è Error parseando JSON del an√°lisis, extrayendo informaci√≥n manualmente');
            
            // Fallback: extraer informaci√≥n del texto
            return {
                timestamp: new Date().toISOString(),
                imageSize: imageBuffer.length,
                text: '',
                objects: [],
                labels: [],
                logos: [],
                faces: [],
                colors: [],
                safety: { isSafe: true },
                landmarks: [],
                summary: resultText.substring(0, 200),
                confidence: 60,
                rawAnalysis: resultText
            };
        }
        
    } catch (error) {
        console.error('‚ùå Error en an√°lisis visual completo:', error);
        
        // Fallback: intentar solo OCR
        try {
            const text = await analyzeImageBufferWithVision(imageBuffer);
            return {
                timestamp: new Date().toISOString(),
                imageSize: imageBuffer.length,
                text: text,
                objects: [],
                labels: [],
                logos: [],
                faces: [],
                colors: [],
                safety: { isSafe: true },
                landmarks: [],
                summary: text ? `Imagen con texto: ${text.substring(0, 100)}...` : 'Imagen procesada pero no se pudo analizar completamente',
                confidence: text ? 70 : 30,
                error: 'An√°lisis parcial - solo OCR disponible'
            };
        } catch (fallbackError) {
            console.error('‚ùå Error en fallback OCR:', fallbackError);
            return {
                timestamp: new Date().toISOString(),
                imageSize: imageBuffer.length,
                text: '',
                objects: [],
                labels: [],
                logos: [],
                faces: [],
                colors: [],
                safety: { isSafe: true },
                landmarks: [],
                summary: 'Imagen procesada pero no se pudo analizar',
                confidence: 0,
                error: 'An√°lisis fallido'
            };
        }
    }
}

/**
 * Detecta el tipo MIME de una imagen bas√°ndose en los magic bytes
 * @param buffer - Buffer de la imagen
 * @returns Tipo MIME de la imagen
 */
function detectImageMimeType(buffer) {
    if (!buffer || buffer.length < 4) {
        return 'image/jpeg'; // Default
    }
    
    // Verificar magic bytes
    const header = buffer.slice(0, 4);
    
    // JPEG: FF D8 FF
    if (header[0] === 0xFF && header[1] === 0xD8 && header[2] === 0xFF) {
        return 'image/jpeg';
    }
    
    // PNG: 89 50 4E 47
    if (header[0] === 0x89 && header[1] === 0x50 && header[2] === 0x4E && header[3] === 0x47) {
        return 'image/png';
    }
    
    // GIF: 47 49 46 38
    if (header[0] === 0x47 && header[1] === 0x49 && header[2] === 0x46 && header[3] === 0x38) {
        return 'image/gif';
    }
    
    // WebP: 52 49 46 46 ... 57 45 42 50
    if (header[0] === 0x52 && header[1] === 0x49 && header[2] === 0x46 && header[3] === 0x46) {
        if (buffer.length > 11 && buffer[8] === 0x57 && buffer[9] === 0x45 && buffer[10] === 0x42 && buffer[11] === 0x50) {
            return 'image/webp';
        }
    }
    
    // BMP: 42 4D
    if (header[0] === 0x42 && header[1] === 0x4D) {
        return 'image/bmp';
    }
    
    // Default a JPEG
    return 'image/jpeg';
}

// Funciones auxiliares exportadas para compatibilidad
export function generateImageSummary(analysis) {
    return analysis.summary || 'Imagen analizada';
}

export function calculateOverallConfidence(analysis) {
    return analysis.confidence || 0;
}